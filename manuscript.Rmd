---
title: "Containers and R: the Rockerverse and beyond"
author:
  - name: Daniel Nüst
    affiliation: Institute for Geoinformatics, University of Münster
    address:
    - Heisenbergstr. 2, 48149 Münster, Germany
    email: daniel.nuest@uni-muenster.de
  - name: Carl Boettiger
    #affiliation: -
    #email: -
  - name: Robrecht Cannoodt
    #affiliatin: -
    #email: -
  - name: Dirk Eddelbuettel
    affiliation: University of Illinois at Urbana-Champaign
    email: dirkd@eddelbuettel.com
  - name: Mark Edmondson
    affiliation: IIH Nordic A/S, Google Developer Expert for GCP
    email: mark@markedmondson.me
  - name: Colin Fay
    affiliation: ThinkR
    email: contact@colinfay.me
  - name: Ben Marwick
    #affiliation: -
    #email: -
  - name: Karthik Ram
    affiliation: Berkeley Institute for Data Science, University of California, Berkeley, CA 94720 USA
    email: karthik.ram@berkeley.edu
  - name: Noam Ross
    #affiliation: -
    #email: -
  - name: Nan Xiao
    affiliation: Seven Bridges Genomics
    address: "529 Main St, Suite 6610 \\newline Charlestown, MA 02129, USA \\newline ORCiD: 0000-0002-0250-5673"
    email: me@nanx.me
  - name: Lori Shepherd
    affiliation: Roswell Park Comprehensive Cancer Center
    address:
    - Elm & Carlton Streets, Buffalo, New York, 14263 USA
    email: lori.shepherd@roswellpark.org
  - name: Nitesh Turaga
    affiliation: Roswell Park Comprehensive Cancer Center
    address:
    - Elm & Carlton Streets, Buffalo, New York, 14263 USA
    email: nitesh.turaga@roswellpark.org
abstract: >
  The Rocker project provides widely-used Docker images for R across different application scenarios.
  This articles surveys describe downstream projects building upon Rocker.
  We also look beyond Rocker to other projects connecting containerisation with R.
  These use cases and the diversity of applications demonstrate the power of Rocker and containerisation for collaboration, effectivity, scalability, and transparency.
# blank footnote? https://tex.stackexchange.com/questions/170511/footnotes-without-numbering
preamble: >
  \usepackage{longtable}
  \usepackage{hyperref}
output: rticles::rjournal_article
#  includes:
#    in_header: preamble.tex
---

# Introduction

The R community keeps growing: the number of new packages on CRAN keeps on rising, meetups, conferences, online courses and unconferences prosper, and the uptake in education and industry increases [REFs].
All this cements the role of R as the lingua franca of statistics, data visualisation, and computational research.
Coinciding with the rise of R was the advent of Docker [CITATION?] as a general tool for development, distribution, and deployment of software.
Combining both these topics, the _Rocker Project_([https://www.rocker-project.org/](https://www.rocker-project.org/)) was introduced in 2014 and provides a number of [Docker](https://en.wikipedia.org/wiki/Docker_(software)) images for various use cases as described in \citet{RJ-2017-065}.
The considerable uptake and continued evolution of the  _Rocker_ suite of containers has lead to numerous projects extending or building upon _Rocker_ images ranging from reproducible research to production deployments.
This article presents this _Rockerverse_ of projects.
It also introduces related activities connecting the R language and environment with other containerisation solutions.
The main contributions is a coherent picture of the current lay of the land of containers in, with, and for `R`.
This diversity includes demonstrators, early prototypes, and mature projects.

# Containerization and Rocker

_Do we need a generic intro here?_ DE: Yes, and happy to take a stab.

# Container Images

## Images for alternative R distributions

As outlined above, R is a widely-used language with a large community.
The large number of extension packages provides access to an unrivaled variety of established and upcoming features.
Nevertheless, special use cases and experimental projects exist to test approaches or provide features different to what _"base R"_ provides.
These projects stem both form academia and industry.
_Base R_, sometimes called `GNU-R`, is the R distribution maintained by the [R Core Team](https://www.r-project.org/contributors.html) and and provided via [CRAN](https://cran.r-project.org/).

_Microsoft R Open_ ([MRO](https://github.com/nuest/mro-docker)) is an R distribution formerly known as Revolution R Open (RRO) before Revolution Analytics was acquired by Microsoft.
MRO is compatible with main R and it's packages.sss
"It includes additional capabilities for improved performance, reproducibility, and platform support." \citep{microsoft_mro}
Most notably these capabilities are the MRAN repository a.k.a. CRAN Time Machine, which is enabled by default, and the (optional) integration with [Intel® Math Kernel Library](https://software.intel.com/en-us/mkl) (MKL) for multi-threading in linear algebra operations \citep{microsoft_multithread}.
<!-- MRAN is also used by versioned Rocker images. -->
MRO does not provide official Docker images, but a set of community-maintained `Dockerfile`s and Docker images `nuest/mro` are available on Docker Hub at [https://github.com/nuest/mro-docker](https://github.com/nuest/mro-docker) and on GitHub at [https://github.com/nuest/mro-docker](https://github.com/nuest/mro-docker) respectively.
The images are inspired by the Rocker images and can be used much in the same fashion, effectively a drop-in replacement allowing users to quickly evaluate if the benefits of MRO + Intel® MKL apply to their use case.
Version-tagged images are provided for the latest bugfix release of recent R versions.
Extended license information about MKL is printed at every startup.

_Renjin_ is an interpreter for the R language running on top of the [Java Virtual Machine](https://en.wikipedia.org/wiki/Java_virtual_machine) (JVM) providing full two-way access between Java and R code \citep{wikipedia_renjin_2018}.
It was developed to combine the benefits of R, such scripting and extension packages, with the JVM's advantages in the areas of security, cross-platform availability, and established position in enterprise settings.
R extension packages need to be specially compiled and are distributed via the Java package manager [Apache Maven](https://en.wikipedia.org/wiki/Apache_Maven), cf. [http://packages.renjin.org/packages](http://packages.renjin.org/packages) for available packages.
Packages are loaded on demand, i.e. at the first call to `library()`.
Not all R packages, especially one linking to binary libraries, are available, e.g. `rgdal` \footnote{\href{http://packages.renjin.org/package/org.renjin.cran/rgdal/1.4-4/build/1}{http://packages.renjin.org/package/org.renjin.cran/rgdal/1.4-4/build/1}}.

There are no offical Docker images for Renjin, but community-maintained images for selected releases only are available under `nuest/renjin` on Docker Hub and GitHub at [https://hub.docker.com/r/nuest/renjin](https://hub.docker.com/r/nuest/renjin) and [https://github.com/nuest/renjin-docker](https://github.com/nuest/renjin-docker) respectively.
These images expose the command line interface of Renjin in a similar fashion as Rocker images and allow an easy evaluation of Renjin's suitability, but are not intended for production use.

[_pqR_](http://www.pqr-project.org/) is a "a pretty quick version of R".
_pqR_ fixes some opinionated issues in the R language and is the basis for experimental features, e.g. automatic diffentiation\footnote{ \href{https://riotworkshop.github.io/abstracts/riot-2019-pqr.txt}{https://riotworkshop.github.io/abstracts/riot-2019-pqr.txt}}.
The source code development [on GitHub](https://github.com/radfordneal/pqR/) is a one man project and it does not provide any Docker images.
But especially disruptive approaches may contribute to the development of the R ecosystem, so the `nuest/pqr` images on Docker Hub and GitHub at [https://hub.docker.com/r/nuest/pqr/](https://hub.docker.com/r/nuest/pqr/) and [https://github.com/nuest/pqr-docker](https://github.com/nuest/pqr-docker) respectively.

_FastR_ is "A high-performance implementation of the R programming language, built on GraalVM" (https://github.com/oracle/fastr).
It is developed by Oracle, connects R to the GraalVM ecosystem \citep{wikipedia_graalvm_2019}, and also claims superior performance but also targets full compatibility with base R \footnote{ \href{https://github.com/oracle/fastr}{https://github.com/oracle/fastr}}.

There are no offical Docker images provided, but `nuest/fastr-docker` provides image and `Dockerfile` on Docker Hub and GitHub at []() and [https://github.com/nuest/fastr-docker](https://github.com/nuest/fastr-docker) respectively.

While the images presented in this section are far from being as vetted, stable, and widely used as any of the _Rocker_ images, they demonstrate an important advantage of containerisation technology, namely the abiliy to transparently build portable stacks of open source software and make them easily accessible to users.
All different distributions are published under GPL licenses.
Since all of the different R distributions claim better performance as a core motivation, a comparision based on Docker images, potentially leveraging the [resource restriction mechanisms](https://docs.docker.com/config/containers/resource_constraints/) of Docker to level the playing field, seems useful future work.

## Bioconductor

[_Bioconductor_](http://bioconductor.org/help/docker/) is an open source, open development project for the analysis and comprehension of genomic data \citep{gentleman_bioconductor_2004}.
The project consists of 1741 R software packages as of August 15th 2019, as well as packages containing annotation or experiment data.
_Bioconductor_has a semiannual release cycle, each release is associated with a particular version of R.
Docker images allow availability of current and past versions of _Bioconductor_ for convenience and reproducibility.

_Bioconductor_ 'base' docker images are built on top of `rocker/r-ver` and `rocker/rstudio`.
_Bioconductor_ installs packages based on the R version, and therefore uses `rocker/rstudio` and `rocker/r-ver` version tagging.
_Bioconductor_ selects the desired version of R from _Rocker_, adds the BiocManager CRAN package for installing appropriate versions of _Bioconductor_ packages, and creates a _Bioconductor_ docker image with an informative tag (R\_version\_Bioc\_version).
The images are summarized on the _Bioconductor_ web site (https://bioconductor.org/help/docker/), maintained on GitHub ([https://github.com/Bioconductor/bioc_docker](https://github.com/Bioconductor/bioc_docker)), and available to the community through [DockerHub](https://hub.docker.com/).
Past and current combinations of R and _Bioconductor_ are therefore accessible via a specific docker tag.

_Bioconductor_ has several images in addition to 'base', specific to various areas of research.
The 'core' image installs the most commonly used _Bioconductor_ packages.
_Bioconductor_ images for proteomics, metabolomics, and flow cytometry are community maintained.
All community maintained images build on top of the _Bioconductor_ base image and therefore indirectly the _Rocker_ images.
To simplify building and maintaining _Bioconductor_ images, we use a Ruby templating engine.

A recent audit of our Dockerfiles, following best practices from the Docker website, led to a reduction in the size and number of layers in images we produce.
The most important insights involve the ['union' file system used by Docker](https://docs.docker.com/storage/storagedriver/overlayfs-driver/#how-container-reads-and-writes-work-with-overlay-or-overlay2).
In this file system, once a layer (e.g., `RUN` statement) writes to a file path, the file path is never altered.
A subsequent layer that might appear to remove or overwrite the path actually masks, rather than alters, the original.
It is therefore important to clean up (e.g., cache removal) within each layer, and to avoid re-installing existing dependencies.

A recent innovation is to produce a `bioconductor_full` image to emulate the _Bioconductor_ nightly Linux build machine.
The image contains the _system dependencies_ needed to install and check almost all (1730 of 1741) _Bioconductor_ software packages.
Users no longer have to manage complciated system dependencies.
The image is configured so that `.libPaths()` has `/usr/local/lib/R/host-site-library` as the first location.
Users mounting a location on the host file system to this location then persist installed packages across docker sessions or updates.
Many _R_ users pursue flexible work flows tailored to particular analysis needs, rather than standardized work flows.
The `bioconductor_full` image is well-suited to this pattern.
`bioconductor_full` provides developers with a test environment like _Bioconductor_'s build system.

Use of images suggests several interesting possibilities for the _Bioconductor_ project.
Images may be valuable in teaching, where participants pull pre-built images to avoid complicated configuration of their own computing environemnts.
An appeal of this over our current approach (providing Amazon Machine Instances for the duration of the course) is the utility of the image to participant after the course is over.
`bioconductor_full` introduces a common system configuration, so it becomes increasingly sensible for _Bioconductor_ to distribute convenient _binary_ packages.
Images also suggest approaches to more advanced computational models.
For instance, we are exploring use of images for [Helm](https://helm.sh/)-orchestrated [Kubernetes](https://kubernetes.io/) clusters on the Google Cloud Platform.
The user interacts with a manager image based on `bioconductor_full`, configured to perform map-reduce style computations via the BiocParallel package communicating with minimally-configured worker images.
A strength of this approach is that the responsibility for complex software configuration (including customized development) is shifted from the user to the experienced _Bioconductor_ core team.

## Images for (historic) R versions [@ColinFay, @nuest]

- run code with Versions of R: https://srv.colinfay.me/r-online
- old R versions: https://github.com/rocker-org/rocker-versioned/issues/138
- [semantic version tags for Rocker](https://github.com/rocker-org/rocker-versioned/#version-tags)
- debugging memory problems across multiple versions: https://github.com/wch/r-debug
- cross-R testing: Show how you can run the same script in multiple R variants in containers (new contribution). Ideally the images should be created using `containerit` and controlled with `stevedore`/`docker`, i.e. via an R script.

## Windows Images [@nuest]

- [rocker-win](https://github.com/nuest/rocker-win)
- is possible, only relevant in organisations with an existing Windows Server-based infrastructure, can meet policies then

## Non-Debian Linux images [NN]

- Alpine images
- [Images used by R-Hub](https://github.com/r-hub/rhub-linux-builders) (overlap with CI?)
- https://github.com/jlisic/R-docker-centos

# R Packages

## Packages for automation and packaging [@nuest]

- [`containerit`](https://github.com/o2r-project/containerit/)
- [`dockertest`](https://github.com/traitecoevo/dockertest/)

### liftr

[_liftr_](https://nanx.me/liftr/) \citep{liftr2019} aims to solve the problem of persistent reproducible reporting in statistical computing.
Currently, the R Markdown format and its backend compilation engine _knitr_ offer a _de facto_ standard for creating dynamic documents \citep{xie2018}.
However, the reproducibility of such content authoring environments is often limited to individual machines --- it is not easy to replicate the system environment (libraries, R versions, R packages) where the document was compiled.
This issue becomes even more serious when it comes to collaborative document authoring and creating large-scale document building services.
_liftr_ solves this reproducibility problem by bringing Docker to the game.
In essence, _liftr_ helps R Markdown users create and manage Docker containers for rendering the documents, thus make the computations utterly reproducible across machines and systems.

On implementation, with no side effects, _liftr_ extended and introduced new metadata fields to R Markdown, allowing users to declare the dependencies for rendering the document.
_liftr_ parses such fields and generates a `Dockerfile` for creating Docker containers.
_liftr_ then helps render the document inside the created Docker container.
This workflow is summarized in Figure \ref{figure:liftr}.

\begin{figure}[htbp]
  \centering
  \includegraphics[width=\textwidth]{liftr-workflow}
  \caption{The liftr workflow for rendering containerized R Markdown documents.}
  \label{figure:liftr}
\end{figure}

_knitr_ and R Markdown are used as the template engine to generate the `Dockerfile`.
Features such as caching container layers for saving image build time, automatic housekeeping for fault-tolerant builds, and Docker status check are supported by _liftr_.
Four RStudio addins are also offered by _liftr_ to allow push-button compilation of documents and provide better IDE integrations.

Three basic principles are followed to design the _liftr_ package since its inception.

1. Continuous reproducibility.
Continuous integration, continuous delivery, and continuous deployment are well-accepted practices in software engineering.
Similarly, it is believed by the authors of _liftr_ that ensuring computational reproducibility means a continuous process instead of creating static data/code archives or a one-time deal.
Specifically, the software packages used in data analysis should be upgraded regularly in a manageable way.
Therefore, _liftr_ supports specifying particular versions of package dependencies, while users are encouraged to always use the latest version of packages (without a version number) by default.

2. Document first.
Many data analysis workflows could be wrapped as either R packages or dynamic documents.
In _liftr_, the endpoint of dynamic report creation is the focus of containerization, because this offers more possibilities for organizing both computations and documentation.
Users are encouraged to start thinking from the visible research output from the first day.

3. Minimal footprint.
R Markdown and Docker are already complex software systems.
Making them work together seamlessly can be complicated.
Therefore, API designs such as function arguments are simplified while being kept as expressive and flexible as possible.

In summary, _liftr_ tries to redefine the meaning of computational reproducibility by offering system-level reproducibility for data analysis.
It provided a practical way for achieving it --- a new perspective on how reproducible research could be done in reality.
Further, sharing system environments for data analysis also becomes extremely easy, since users only need to share the R Markdown document (with a few extra metadata fields), and compile them with _liftr_.
As an example, _liftr_ demonstrated its advantage for R Markdown-based computational workflow orchestration, by effortlessly containerizing 18 complex _Bioconductor_ workflows in the DockFlow project (https://dockflow.org) in 2017.

- [`rize` for Shiny](https://github.com/cole-brokamp/rize)
- [`dockerfiler`](https://github.com/ColinFay/dockerfiler)

## Packages for control and provisioning [@nuest, @richfitz, @rcannood]

- [`stevedore`](https://github.com/richfitz/stevedore)
- [`babelwhale`](https://cran.r-project.org/web/packages/babelwhale/index.html): Running a Docker from R with Singularity or Docker as back-end. This is really useful in HPC environments where a user might not have root access but is able to install Singularity instead of Docker. [@rcannood]
- [`docker`](https://bhaskarvk.github.io/docker/)
- `RSelenium`
- [`googleComputeEngineR`](https://cloudyr.github.io/googleComputeEngineR/) (function `docker_run`)
  - I don't think `docker_run` is main focus for containers for this package, its more how it uses Docker to launch custom environments that can be templated (e.g. rstudio, shiny etc.) and for parrallisation e.g. `library(future)`  using GCE VMs as endpoints. [@MarkEdmondson1234]
- [`analogsea`](https://github.com/sckott/analogsea)
- [`harbor`](https://github.com/wch/harbor/)
- [`dockermachine`](https://github.com/cboettig/dockermachine)

# Use cases and applications

## Continuous integration and continuous delivery [@noamross, @ColinFay]

- R-Hub
- DevOps
  - https://www.opencpu.org/posts/opencpu-with-docker/
- `r-ci`: https://github.com/ColinFay/r-ci
- [dynwrap](https://github.com/dynverse/dynwrap_containers/blob/master/.travis.yml) [@rcannood]
  - For this project, we use travis-ci to build rocker-derived containers, test them, and only push them to docker hub (from travis-ci.org) if the integration tests succeed.
- Google Cloud Build [@MarkEdmondson1234]
  - https://cloud.google.com/cloud-build/
  - For me this is what makes Docker containers viable, as it builds the Dockerfiles on each GitHub commit.  It couples with Google Container Registry to build private Docker images, for downstream applications.

## Common or public work environments [div]

- Binder

The [Binder project](https://mybinder.readthedocs.io/en/latest/), maintained by the team behind Jupyter, makes it possible for users to create and share their computing environments with others. A deployed version of this service called binder hub allows anyone with access to a web browser and an internet connection to launch a temporary instance of these custom environments and execute any notebooks contained within. From a reproducibility standpoint, Binder makes it exceedingly easy to compile a paper, visualize data, and run small examples from papers or tutorials without the need for any local installation. 

To set up Binder for a project, a user typically starts at an instance of a Binderhub (examples include mybinder.org and binder.pangeo.io) and passes the location of a hosted Git repository. Using internal tools such as [repo2docker](https://repo2docker.readthedocs.io/en/latest/config_files.html), the binderhub builds a Dockerfile by parsing the contents of all code contained within. While this approach works well for most run of the mill Python projects, it is not so seamless for R projects. For any R projects that use the Tidyverse suite [citation in review], the time and resources required to build all dependencies from source can often time out before completion, making it frustrating for the average R user. 

[`holepunch`](https://github.com/karthik/holepunch) is a R package that was designed to remove some of these limitations and make Binder more accessible to novice R users. `holepunch` achieves this by leveraging Rocker images that contains the Tidyverse along special Jupyter dependencies, and only installs additional packages from CRAN and Bioconductor that are not already part of these images. Starting with the Binder/Tidyverse base images eliminates a large part of the build time and in most cases results in a binder instance launching within a minute. `holepunch` as a side effect also creates a DESCRIPTION file which then turns any project into a research compendium [Marwick et al]. The Dockerfile included with the project can also be used to launch a RStudio server locally independent of binder which is especially useful when more computational resources are required.


  - [`repo2docker`](https://repo2docker.readthedocs.io/en/latest/config_files.html) (`install.R`, `DESCRPTION`, `runtime.txt`) based on the Rocker images [@nuest]
- GPU [@noamross, @cboettig]
- Gigantum stack
- in education (ready to use teaching/learning environments)
  - [`r-db`](https://github.com/ColinFay/r-db) [@ColinFay]
- [RCloud](https://github.com/att/rcloud/tree/master/docker) ?

## Deployment, processing, cloud [div]

- Docker images for cloud services [@MarkEdmondson1234]
  - the most popular functionality for `googleComputeEngineR` is its use of Docker to enable parallel processing across VMS - [some demos here](https://cloudyr.github.io/googleComputeEngineR/articles/massive-parallel.html)
- Google Cloud Run - CaaS (Containers as a Service) that lets you launch a Docker container without worrying about underlying infrastructure. An R implementation is shown here at [cloudRunR](https://github.com/MarkEdmondson1234/cloudRunR) which uses it to create a scalable R plumber API. 
- [`plumber`](https://www.rplumber.io/docs/hosting.html#docker)
- `batchtools` \citep{Lang2017batchtools} can [schedule jobs with Docker Swarm](https://mllg.github.io/batchtools/reference/makeClusterFunctionsDocker.html)
- scalable deployments, e.g. start with numerous Shiny talks mentioning Rocker at useR!2017
- [dynmethods](https://github.com/dynverse/dynmethods) [@rcannood]: In order to evaluate ±50 computational methods which all used different environments (R, Python, C++, ...), we wrapped each of them in a docker container and can execute these methods from R. Again, all of these containers are being built on travis-ci, and will only be pushed to docker hub if the integration test succeeds.
- [ShinyProxy](https://www.shinyproxy.io/) [creates a container](https://github.com/openanalytics/shinyproxy/blob/master/src/main/java/eu/openanalytics/services/DockerService.java#L388) for each user

## Research Compendia [@benmarwick]

...

# Other containerisation platforms [NN]

- R images for Singularity
- Running Rocker images with
  - Singularity
  - CoreOS rkt?
- nix?

# Discussion/outlook/conclusion [@all, please add bullet points]

- Missing pieces?
- consolidation (e.g. via packages using `dockerfiler` and `stevedore`)
- Common themes
  - reproducibility
- will knowledge about containers continue to spread?
- what is needed for even more containers with R?
- the ability to move processing between services easily (e.g locally, one cloud providers VM, another cloud provider's Container-as-a-Service)
- ...

# Author contributions

DN conceived of the presented idea and \href{https://github.com/nuest/rockerverse-paper/issues/3}{initialised the formation of the writing team}.
CB ..
RC ..
DE ..
ME ..
CF ..
BW ..
KR ..
NR ..
NX wrote the section on liftr.
LS \& NT wrote the section on Bioconductor.
All authors contributed to the discussion and outlook section and approved the final version.
This articles was collaboratively written at \href{https://github.com/nuest/rockerverse-paper/}{https://github.com/nuest/rockerverse-paper/}.
The \href{https://github.com/nuest/rockerverse-paper/graphs/contributors}{contributors page} and \href{https://github.com/nuest/rockerverse-paper/commits/master}{commit history} provide a detailed view on the respective contributions.

\bibliography{RJreferences}
